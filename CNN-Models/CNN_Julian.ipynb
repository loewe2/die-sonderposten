{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dfa08c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01046257-5167-465b-b119-42d118db081b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn\n",
    "# !pip install scikit-image\n",
    "# !pip install statsmodels\n",
    "# !pip install tensorflow\n",
    "# !pip install pydot\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d0ff50-edab-4940-ae65-de168fef9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"training.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc002ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wettbewerb import load_references, save_predictions\n",
    "from preprocess import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191dbd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e211183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ecg_leads, ecg_labels, fs, ecg_names = load_references(folder='/shared_data/training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d7172",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58542dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_leads_edited = ecg_leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0884f",
   "metadata": {},
   "source": [
    "### Noise removal (fan_multiscaled_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3f82af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered = []\n",
    "for j, data in enumerate(ecg_leads_edited):\n",
    "    data_ftt, freq = ecg_furier(ecg_leads_edited[j], fs)\n",
    "    lowpassed = ecg_denoise_spectrum(data_ftt, freq, 0, 60)\n",
    "    filtered.append(ecg_invfurier(lowpassed))\n",
    "\n",
    "ecg_leads_edited = filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5707d67",
   "metadata": {},
   "source": [
    "### Z-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf7ef2a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered = []\n",
    "for j, data in enumerate(ecg_leads_edited):\n",
    "    filtered.append(ecg_norm(ecg_leads_edited[j]))\n",
    "\n",
    "ecg_leads_edited = filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c37446-9c40-4bb4-b388-a19e052fdf59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Length normalization (hsieh_detection_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e71ea78-7b38-42d8-8a3d-ea2b9ad833e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_split(data, limit, label):\n",
    "    splitted = []\n",
    "    ratio = len(data)/limit\n",
    "\n",
    "    # If data is longer than limit, split with at least 50% overlap\n",
    "    if ratio > 1:\n",
    "        for i in range(0, int(np.ceil(2*ratio))):\n",
    "            if i == int(np.ceil(2*ratio))-1:\n",
    "                string = data[len(data)-limit:len(data)]\n",
    "            else:\n",
    "                string = data[int(np.floor(i*limit/2)):int(np.floor(i*limit/2+limit))]\n",
    "            splitted.append(string)\n",
    "        splitted = [x for x in splitted if x.shape[0] >= limit] # remove string which are shorter\n",
    "        labels_multiplied = [label] * len(splitted)\n",
    "\n",
    "    # If data is shorter than limit, add from the beginning\n",
    "    elif ratio < 1:\n",
    "        if ratio <= 0.5:\n",
    "            data = np.tile(data, int(np.floor(1/ratio)))\n",
    "        diff = limit - len(data)\n",
    "        appended_data = data[0:diff]\n",
    "        data = np.append(data, appended_data)\n",
    "        splitted.append(data)\n",
    "        labels_multiplied = [label] * 1\n",
    "\n",
    "    # If it is the exact length, then don't alter it\n",
    "    elif ratio == 1:\n",
    "        splitted.append(data)\n",
    "        labels_multiplied = [label] * 1\n",
    "    return splitted, labels_multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9956d375-d243-44f7-b050-196890bf9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = []\n",
    "normalized_label = []\n",
    "time_set = 30\n",
    "duration = time_set*fs\n",
    "for j, data in enumerate(ecg_leads_edited):\n",
    "    ecg_split_data, lab_mul = ecg_split(data, duration, ecg_labels[j])\n",
    "    normalized.extend(ecg_split_data)\n",
    "    normalized_label.extend(lab_mul)\n",
    "\n",
    "ecg_leads_edited = normalized\n",
    "ecg_labels_edited = normalized_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688742a9-1139-495b-8944-1ac174cba3fc",
   "metadata": {},
   "source": [
    "### Split training, validation, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5576ce55-cb5b-4a52-ab02-40ffd31b7b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(ecg_leads_edited, ecg_labels_edited, test_size=0.2, shuffle = True, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c7ba090-4708-4bd1-aa77-0c6ef4ce7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef25a45-3bd5-4553-923f-223da86cf61f",
   "metadata": {},
   "source": [
    "### Random oversampling for imbalanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a81336e8-3967-4927-b3d9-988fc7249dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0, sampling_strategy='minority')\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Converts sublists to arrays\n",
    "xfiltered = []\n",
    "yfiltered = []\n",
    "for j, data in enumerate(X_train):\n",
    "    xfiltered.append(np.asarray(X_resampled[j]))\n",
    "    yfiltered.append(np.asarray(y_resampled[j]))\n",
    "X_train = xfiltered\n",
    "y_train = yfiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15646a95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Label encoding (0: A, 1: N, 2: O, 3: ~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c279e0a5-dc5d-4f3c-94d6-452d77f5cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get indices for each label\n",
    "# idx_N = [i for i in range(len(ecg_labels_edited)) if ecg_labels_edited[i] == 'N']\n",
    "# idx_A = [i for i in range(len(ecg_labels_edited)) if ecg_labels_edited[i] == 'A']\n",
    "# idx_tilde = [i for i in range(len(ecg_labels_edited)) if ecg_labels_edited[i] == '~']\n",
    "# idx_O = [i for i in range(len(ecg_labels_edited)) if ecg_labels_edited[i] == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07212e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelencode(y_data):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_data)\n",
    "    encoded = le.transform(y_data)\n",
    "    encoded = keras.utils.to_categorical(encoded)\n",
    "    return encoded\n",
    "\n",
    "def tolist(array):\n",
    "    liste = []\n",
    "    for i, data in enumerate(array):\n",
    "        liste.append(data)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a21210b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = []\n",
    "# for p, data in enumerate(ecg_labels_edited):\n",
    "#     d.append(\n",
    "#         {\n",
    "#             'ecg_data': ecg_names[p],\n",
    "#             'label': ecg_labels_enc[p]\n",
    "#         }\n",
    "#     )\n",
    "# features_names = pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75aee684-7ad1-40a1-b1d4-dbc957df054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical & one-hot encode\n",
    "y_train = labelencode(y_train)\n",
    "y_test = labelencode(y_test)\n",
    "\n",
    "# Convert to list\n",
    "y_train = tolist(y_train)\n",
    "y_test = tolist(y_test)\n",
    "\n",
    "# Convert to array... x=(samples, time), y=(samples, encodings)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e7e8d4e-9bfb-4426-949e-97e2e9099f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(xfiltered, yfiltered, X_resampled, y_resampled, ros, ecg_leads_edited, normalized, ecg_labels_edited, normalized_label, ecg_leads, ecg_labels, fs, ecg_names, filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72425f1-3a69-4e79-b0de-9bb77eee8f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification (CNN)\n",
    "- Sources:\n",
    "    - https://stackoverflow.com/questions/55233377/keras-sequential-model-with-multiple-inputs\n",
    "    - https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "    - https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "    - https://www.tutorialspoint.com/keras/keras_convolution_neural_network.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81737b6-ca40-46c5-9ba6-535195b08483",
   "metadata": {},
   "source": [
    "### CNN-defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3122c92e-2e46-4976-ac3f-79b9a7e515f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d(filters, kernel_size, act='relu'):\n",
    "    layer = tf.keras.layers.Conv1D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=1,\n",
    "        activation=act,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        data_format=\"channels_last\",\n",
    "        padding=\"valid\",\n",
    "        # dilation_rate=1,\n",
    "        # groups=1,\n",
    "        # kernel_regularizer=None,\n",
    "        # bias_regularizer=None,\n",
    "        # activity_regularizer=None,\n",
    "        # kernel_constraint=None,\n",
    "        # bias_constraint=None\n",
    "        )\n",
    "    return layer\n",
    "\n",
    "def maxpool(stride_num, pool_num=2):\n",
    "    layer = tf.keras.layers.MaxPooling1D(\n",
    "        strides=stride_num,\n",
    "        pool_size=pool_num,\n",
    "        padding=\"valid\",\n",
    "        # data_format=\"channels_last\"\n",
    "        )\n",
    "    return layer\n",
    "\n",
    "def fully(uni, act='relu'):\n",
    "    layer = tf.keras.layers.Dense(\n",
    "        units=uni,\n",
    "        activation=act,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=keras.regularizers.L2(1e-3),\n",
    "        # bias_regularizer=None,\n",
    "        # activity_regularizer=None,\n",
    "        # kernel_constraint=None,\n",
    "        # bias_constraint=None\n",
    "        )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d00f80-1da5-4a47-8f79-1b784e01fc02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CNN (fan_multiscaled_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3851b00-27c2-44a6-a4ed-796294dbe639",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = None\n",
    "epochen = 20\n",
    "num_classes = 4\n",
    "X_tr = X_train\n",
    "y_tr = y_train\n",
    "X_te = X_test\n",
    "y_te = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7425a22b-2a08-4e80-b1a1-0bf09dccc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = keras.layers.Input(\n",
    "    shape=(duration,1),\n",
    "    batch_size=batch_s\n",
    ")\n",
    "\n",
    "# First branch\n",
    "line1 = conv_1d(64,3,act=None)(stream)\n",
    "line1 = conv_1d(64,3)(line1)\n",
    "line1 = maxpool(3)(line1)\n",
    "line1 = conv_1d(128,3)(line1)\n",
    "line1 = conv_1d(128,3)(line1)\n",
    "line1 = maxpool(3)(line1)\n",
    "line1 = conv_1d(256,3)(line1)\n",
    "line1 = conv_1d(256,3)(line1)\n",
    "line1 = conv_1d(256,3)(line1)\n",
    "line1 = maxpool(2)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1 = maxpool(2)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1 = conv_1d(512,3)(line1)\n",
    "line1_out = maxpool(2)(line1)\n",
    "line1_mod = keras.Model(inputs=stream, outputs=line1_out)\n",
    "\n",
    "# Second branch\n",
    "line2 = conv_1d(64,7,act=None)(stream)\n",
    "line2 = conv_1d(64,7)(line2)\n",
    "line2 = maxpool(3)(line2)\n",
    "line2 = conv_1d(128,7)(line2)\n",
    "line2 = conv_1d(128,7)(line2)\n",
    "line2 = maxpool(3)(line2)\n",
    "line2 = conv_1d(256,3)(line2)\n",
    "line2 = conv_1d(256,3)(line2)\n",
    "line2 = conv_1d(256,3)(line2)\n",
    "line2 = maxpool(2)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2 = maxpool(2)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2 = conv_1d(512,3)(line2)\n",
    "line2_out = maxpool(2)(line2)\n",
    "line2_mod = keras.Model(inputs=stream, outputs=line2_out)\n",
    "\n",
    "# Combination\n",
    "combined = keras.layers.Concatenate()([line1_mod.output, line2_mod.output])\n",
    "combined = keras.layers.Flatten()(combined)\n",
    "\n",
    "# Fully connected layer\n",
    "line3 = fully(1024, act=None)(combined)\n",
    "line3 = fully(1024)(line3)\n",
    "line3 = fully(256)(line3)\n",
    "outputs = fully(num_classes, act=\"softmax\")(line3)\n",
    "model = keras.Model(inputs=stream, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea383ef2-cb34-4e1f-b7f3-3a81bcab3cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 9000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_193 (Conv1D)            (None, 8998, 64)     256         ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_206 (Conv1D)            (None, 8994, 64)     512         ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_194 (Conv1D)            (None, 8996, 64)     12352       ['conv1d_193[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_207 (Conv1D)            (None, 8988, 64)     28736       ['conv1d_206[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_75 (MaxPooling1D  (None, 2999, 64)    0           ['conv1d_194[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_80 (MaxPooling1D  (None, 2996, 64)    0           ['conv1d_207[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_195 (Conv1D)            (None, 2997, 128)    24704       ['max_pooling1d_75[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_208 (Conv1D)            (None, 2990, 128)    57472       ['max_pooling1d_80[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_196 (Conv1D)            (None, 2995, 128)    49280       ['conv1d_195[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_209 (Conv1D)            (None, 2984, 128)    114816      ['conv1d_208[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_76 (MaxPooling1D  (None, 998, 128)    0           ['conv1d_196[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_81 (MaxPooling1D  (None, 995, 128)    0           ['conv1d_209[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_197 (Conv1D)            (None, 996, 256)     98560       ['max_pooling1d_76[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_210 (Conv1D)            (None, 993, 256)     98560       ['max_pooling1d_81[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_198 (Conv1D)            (None, 994, 256)     196864      ['conv1d_197[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_211 (Conv1D)            (None, 991, 256)     196864      ['conv1d_210[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_199 (Conv1D)            (None, 992, 256)     196864      ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_212 (Conv1D)            (None, 989, 256)     196864      ['conv1d_211[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_77 (MaxPooling1D  (None, 496, 256)    0           ['conv1d_199[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_82 (MaxPooling1D  (None, 494, 256)    0           ['conv1d_212[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_200 (Conv1D)            (None, 494, 512)     393728      ['max_pooling1d_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_213 (Conv1D)            (None, 492, 512)     393728      ['max_pooling1d_82[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_201 (Conv1D)            (None, 492, 512)     786944      ['conv1d_200[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_214 (Conv1D)            (None, 490, 512)     786944      ['conv1d_213[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_202 (Conv1D)            (None, 490, 512)     786944      ['conv1d_201[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_215 (Conv1D)            (None, 488, 512)     786944      ['conv1d_214[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_78 (MaxPooling1D  (None, 245, 512)    0           ['conv1d_202[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_83 (MaxPooling1D  (None, 244, 512)    0           ['conv1d_215[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_203 (Conv1D)            (None, 243, 512)     786944      ['max_pooling1d_78[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_216 (Conv1D)            (None, 242, 512)     786944      ['max_pooling1d_83[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_204 (Conv1D)            (None, 241, 512)     786944      ['conv1d_203[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_217 (Conv1D)            (None, 240, 512)     786944      ['conv1d_216[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_205 (Conv1D)            (None, 239, 512)     786944      ['conv1d_204[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_218 (Conv1D)            (None, 238, 512)     786944      ['conv1d_217[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_79 (MaxPooling1D  (None, 119, 512)    0           ['conv1d_205[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_84 (MaxPooling1D  (None, 119, 512)    0           ['conv1d_218[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 119, 1024)    0           ['max_pooling1d_79[0][0]',       \n",
      "                                                                  'max_pooling1d_84[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 121856)       0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1024)         124781568   ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 4)            4100        ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 134,715,268\n",
      "Trainable params: 134,715,268\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c550ae-dc79-4c31-8250-26093cacb6de",
   "metadata": {},
   "source": [
    "### Compile & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b554ca37-e319-4804-91de-c45ca3f67cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=300,\n",
    "    decay_rate=0.1)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    # loss_weights=None,\n",
    "    # weighted_metrics=None,\n",
    "    # run_eagerly=None,\n",
    "    # steps_per_execution=None,\n",
    "    # jit_compile=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32d5c68d-ed86-48e4-8260-949ed5b60f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "186/213 [=========================>....] - ETA: 2s - loss: 3.0638 - accuracy: 0.5722"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      4\u001b[0m         filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_julian_\u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#with tf.device('/CPU:0'):\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_te\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# shuffle=True,\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# class_weight=None,\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# sample_weight=None,\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# initial_epoch=0,\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# steps_per_epoch=None,\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_steps=None,\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_batch_size=None,\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_split=0.0,\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_freq=1,\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_queue_size=10,\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# workers=1,\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_multiprocessing=False,\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1221\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1223\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 436\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    353\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 354\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    357\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1032\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1103\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1104\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    549\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 550\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/tljh/user/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1114\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='cnn_julian_{epoch}',\n",
    "        save_freq='epoch',\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        verbose=0,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        patience=2,\n",
    "        mode=\"auto\",\n",
    "        verbose=1,\n",
    "        # min_delta=0,\n",
    "        # baseline=None,\n",
    "        # restore_best_weights=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "#with tf.device('/CPU:0'):\n",
    "model.fit(\n",
    "    x = X_tr,\n",
    "    y = y_tr,\n",
    "    batch_size = batch_s, \n",
    "    epochs = epochen, \n",
    "    verbose = 1,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = (X_te, y_te),\n",
    "    # shuffle=True,\n",
    "    # class_weight=None,\n",
    "    # sample_weight=None,\n",
    "    # initial_epoch=0,\n",
    "    # steps_per_epoch=None,\n",
    "    # validation_steps=None,\n",
    "    # validation_batch_size=None,\n",
    "    # validation_split=0.0,\n",
    "    # validation_freq=1,\n",
    "    # max_queue_size=10,\n",
    "    # workers=1,\n",
    "    # use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4812fb-3521-4e4e-856b-9649b93c45e4",
   "metadata": {},
   "source": [
    "### Test & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015cd96f-27e8-43b5-88f6-21ba9240985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    score = model.evaluate(\n",
    "        x=X_te,\n",
    "        y=y_te,\n",
    "        verbose = 'auto',\n",
    "        # batch_size=None,\n",
    "        # sample_weight=None,\n",
    "        # steps=None,\n",
    "        # callbacks=None,\n",
    "        # max_queue_size=10,\n",
    "        # workers=1,\n",
    "        # use_multiprocessing=False,\n",
    "        # return_dict=False\n",
    "    ) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808a9ee-84fb-4526-81fd-c36b25cf6023",
   "metadata": {},
   "source": [
    "### Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54b2fd-a93b-4ac6-b993-3420a93609d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "Model.save(\n",
    "    filepath=\"cnn_julian.tf\",\n",
    "    include_optimizer=True,\n",
    "    save_format=\"tf\",\n",
    "    # overwrite=True,\n",
    "    # signatures=None,\n",
    "    # options=None,\n",
    "    # save_traces=True,\n",
    ")\n",
    "#loaded_model = tf.keras.models.load_model('/tmp/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcba624-d254-4042-b6c4-7e3f62cca566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model statistics\n",
    "model.summary()\n",
    "print(history.history)\n",
    "#model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce03fc-2d7a-4b50-aeb3-dfed59351322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot model\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    rankdir=\"TB\",\n",
    "    dpi=80,\n",
    "    show_shapes=True,\n",
    "    layer_range=None,\n",
    "    show_layer_names=False,\n",
    "    \n",
    "    # Misc.\n",
    "    # show_dtype=True,\n",
    "    # show_layer_activations=True,\n",
    "    # expand_nested=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a49c2a-5ccc-431e-9451-426749b19938",
   "metadata": {},
   "source": [
    "### Predict & run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4f51a-7e2f-41fb-bd3f-d417d52cbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(\n",
    "    x = X_te,\n",
    "    batch_size=None,\n",
    "    verbose=\"auto\"\n",
    "    \n",
    "    # Misc.\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "pred = np.argmax(pred, axis = 1)[:5] \n",
    "label = np.argmax(y_test,axis = 1)[:5] \n",
    "\n",
    "print(pred)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3fc99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sonstige\n",
    "- [ ] Normalisieren:\n",
    "    - https://keras.io/api/layers/preprocessing_layers/numerical/normalization/\n",
    "    - https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
    "- [ ] Rebalance: https://keras.io/examples/structured_data/imbalanced_classification/\n",
    "- [ ] Schnitttechnik der Daten (nur R-Peaks cutten)\n",
    "- [ ] Alternative Architekturen (notfalls einfach auch nur Code durchgehen, um zu ergnzen):\n",
    "    - https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
    "    - https://keras.io/examples/timeseries/timeseries_classification_transformer/\n",
    "    - https://keras.io/api/data_loading/timeseries/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
